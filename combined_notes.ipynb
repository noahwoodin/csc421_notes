{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CSC 421 - Agents \n",
    "\n",
    "### Instructor: George Tzanetakis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents \n",
    "\n",
    "\n",
    "**EMPHASIS**: Agents as a unifying concept of thinking about AI and software \n",
    "\n",
    "\n",
    "During this lecture we will cover the following topics: \n",
    "\n",
    "1. Agents \n",
    "2. Performance, environments, actuators, sensors \n",
    "3. Agent architectures \n",
    "7. Learning \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## WORKPLAN \n",
    "\n",
    "The section number is based on the 4th edition of the AIMA textbook and is the suggested\n",
    "reading for this week. Each list entry provides just the additional sections. For example the Expected reading include the sections listed under Basic as well as the sections listed under Expected. Some additional readings are suggested for Advanced. \n",
    "\n",
    "1. Basic: Sections **2.1**, **2.3**, **2.4** and Summary  \n",
    "2. Expected: **2.2**\n",
    "3. Advanced: Bibligraphical and historical notes \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents and Environments  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agents** perceive their **environment** through **sensors** and act upon that environment through **actuators**. \n",
    "\n",
    "\n",
    "Terminology: \n",
    "\n",
    "1. Percept \n",
    "2. Percept sequence \n",
    "3. Agent function (abstract mathematical distribution, in many cases infinite tabulation) \n",
    "4. Agent program (concrete implementation running on a physical system) \n",
    "\n",
    "What makes an agent effective, good, intelligent ? \n",
    "\n",
    "\n",
    "Any area of engineering can be viewed through the lenses of agents. What makes AI unique is the significant computational resources that can be employed by the agent and the non-trivial decision making that the task environment requires. In fact one could possibly define AI agents as systems that can not be developed using traditional engineering approaches.\n",
    "\n",
    "<img src=\"images/aima_simple_agent.png\" width=\"70%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEAS Description of Agent \n",
    "\n",
    "1. **Performance** a way to measure how the agent is doing \n",
    "2. **Environment** essential the problems or worlds in which the agent needs to operate \n",
    "3. **Actuators** are the different ways the agent can be interact with the environment as well as possibly its own\n",
    "operation. They receive **actions** that encode the information needed for them to operate. \n",
    "4. **Sensors** are the ways the agent can acquire information about the environment it is operating as well as possibly \n",
    "information about its own operation. The information they acquire is represented as **percepts**.f\n",
    "\n",
    "Let's consider some examples - what are the possible percepts, environments, sensors and actuators for these \n",
    "agents: \n",
    "\n",
    "1.  Human \n",
    "2.  Robot \n",
    "3.  Vacuum cleaner world \n",
    "4.  Single chess piece valid chessboard moves \n",
    "5.  Self-driving car \n",
    "6.  Ant \n",
    "7.  NPC in game \n",
    "8.  Chess playing program \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK ENVIRONMENTS \n",
    "\n",
    "Specifying the task environment (essentially the problem to which rational agents are the solutions): \n",
    "\n",
    "\n",
    "1. Performance \n",
    "2. Environment \n",
    "3. Actuators \n",
    "4. Sensors \n",
    "\n",
    "\n",
    "Properties of task environmets (for each one think of examples or consider the examples mentioned above): \n",
    "\n",
    "1. Fully observable vs partially observable \n",
    "2. Single-agent vs multiagent \n",
    "    1. Competitive multiagent (chess) vs co-operative multiagent (self-driving cars avoiding collisions)\n",
    "3. Deterministic vs nondeterministic \n",
    "\n",
    "\n",
    "**Agent = architecture + program** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of Agents \n",
    "\n",
    "1. **Reflex agents** \n",
    "\n",
    "Reflex agents simply act based on the current percept ignoring the rest of the percept history. They can \n",
    "operate using simple condition-action rules. Humans have many such rules that are typically used when fast action \n",
    "in response to a stimulus is required. \n",
    "\n",
    "<img src=\"images/aima_simple_agent.png\" width=\"70%\"/>\n",
    "\n",
    "2. **Model-based reflex agents**\n",
    "\n",
    "The most effective way for an agent to deal with a partially observable environment is to maintain \n",
    "some kind of internal representation (model) keeping track of the parts of the world that it can not \n",
    "perceive. This model needs to be updated based on knowledge about how the world changes independently of the \n",
    "agent as well as about how the agent's own actions can affect the world. \n",
    "\n",
    "<img src=\"images/aima_model_agent.png\" width=\"70%\"/>\n",
    "\n",
    "\n",
    "\n",
    "5. **Goal-based agents** \n",
    "\n",
    "Knowing something about the current state of the world is not always sufficient in order to decide what to do. There are many situations in which the agent nneds to have some sort of **goal** information that describes situations that are desirable. Goal-based agents are fundementally different than reflex agents as they consider the future. We we will be looking at **Search** (in detail) and **Planning** which are two research areas of AI that focus on finding action sequences for agents to achieve specific goals. Goal agents are more flexible than reflex-agents but in general tend to be more computationally demanding and therefore slower as they need to consider how actions create multiple possible \"futures\" and determine if these **futures** meat specific **goals**. \n",
    "\n",
    "<img src=\"images/aima_goal_agent.png\" width=\"70%\"/>\n",
    "\n",
    "\n",
    "\n",
    "6. **Utility-based agents**\n",
    "   \n",
    "Goals alone are not enough. Utility is an internal representation of the performance measure. You can think of it as a \"happiness\" measure for the agent. Utility has the same relationship with an external performance measure that the internal world representation of an agent has with the actual world/environment it operates. Utility can assist in two situations in which goal-based agents have a hard time: 1) when there are conflicting goals (for example speed and safety) 2) when there are multiple goals that the agent can aim for but none of which can achieved with certainty. Because uncertainty is always present in typical real-world situations requiring rational/intelligent behavior technically speaking a utility-based agent chooses the action that maximizes the **expected utility**. \n",
    "\n",
    "<img src=\"images/aima_utility_agent.png\" width=\"70%\"/>\n",
    "\n",
    "Discussion Examples: \n",
    "NPC in a graph-based text adventure \n",
    "Driving to the airport \n",
    "\n",
    "\n",
    "**IMPORTANT: CLEAR SEPARATION OF AGENT AND ENVIRONMENT WHEN DOING SIMULATIONS**\n",
    "\n",
    "\n",
    "### LEARNING AGENTS \n",
    "\n",
    "All types of agent architectures can benefit from learning. Learning occurs when the peformance measure with which we measure how the agent is doing improves through \"experience\" i.e repeated operation in an environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World/Environment Representations \n",
    "\n",
    "**Imortant note:** The environment representation is different than the environment and it consists of what \n",
    "the agent \"knows\" about it so in most cases it does not contain all the information in the environment. \n",
    "\n",
    "Atomic representation, factored representation, structured representation, distributed representation \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/aima_environment_representations.png\" width=\"70%\"/>\n",
    "\n",
    "\n",
    "* Algorithms for search and game-playing, hidden markov modes, and markov decision processes work with atomic representations. \n",
    "* Constraint satisfaction problems, propositional logic, bayesian networks, and machine learning algorithms frequently work with factored representatinos. \n",
    "* Relational databases, first-order logic, natural language understanding and knowledge-based learning operate on structured representation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code sketch of a reflex agent. The set of rules (condition-action pairs) \n",
    "# can remain static through the execution or can be modified if the agent is capable of learning. \n",
    "\n",
    "def simple_rule_agent(percept, rules): \n",
    "    state = interpet_input(percept)\n",
    "    rule  = rule_match(state,rules) \n",
    "    action = rule.action() \n",
    "    return action\n",
    "\n",
    "# code sketch of a model-based reflex agent \n",
    "# state: the agen'ts current conception of the world state \n",
    "# model: a description of how the next state depends on the current state and action \n",
    "def model_agent(percept, rules, state, model): \n",
    "    state = update_state(state, action, percept, model) \n",
    "    rule = rule_match(state, rules) \n",
    "    action = rule.action() \n",
    "    return action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
